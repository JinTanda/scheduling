{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_ = tf.placeholder(tf.float32,shape=(None,28,28,1))\n",
    "y_ = tf.placeholder(tf.float32,shape=(None,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_104:0\", shape=(?, 7, 7, 50), dtype=float32)\n",
      "(?, 2450)\n",
      "Tensor(\"Variable_303/read:0\", shape=(500,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "conv1_features = 20\n",
    "max_pool_size1 = 2\n",
    "#畳み込み層1\n",
    "conv1_w = tf.Variable(tf.truncated_normal([5,5,1,conv1_features],stddev=0.1), dtype=tf.float32)\n",
    "conv1_b = tf.Variable(tf.constant(0.1,shape=[conv1_features]),dtype=tf.float32)\n",
    "conv1_c2 = tf.nn.conv2d(x_,conv1_w,strides=[1,1,1,1],padding=\"SAME\")\n",
    "conv1_relu = tf.nn.relu(conv1_c2+conv1_b)\n",
    "conv1_mp = tf.nn.max_pool(conv1_relu, ksize=[1,max_pool_size1,max_pool_size1,1],strides=[1,max_pool_size1,max_pool_size1,1],padding=\"SAME\")\n",
    "#畳み込み層2\n",
    "conv2_features=50\n",
    "max_pool_size2 = 2\n",
    "conv2_w = tf.Variable(tf.truncated_normal([5,5,conv1_features,conv2_features],stddev=0.1),dtype=tf.float32)\n",
    "conv2_b = tf.Variable(tf.constant(0.1,shape=[conv2_features]),dtype=tf.float32)\n",
    "conv2_c2 = tf.nn.conv2d(conv1_mp,conv2_w,strides=[1,1,1,1],padding=\"SAME\")\n",
    "conv2_relu = tf.nn.relu(conv2_c2+conv2_b)\n",
    "conv2_mp = tf.nn.max_pool(conv2_relu,ksize=[1,max_pool_size2,max_pool_size2,1],strides=[1,max_pool_size2,max_pool_size2,1],padding=\"SAME\")\n",
    "print(conv2_mp)\n",
    "#全結合層1\n",
    "result_w = x_.shape[1]\n",
    "result_h = x_.shape[2]\n",
    "fc_input_size = result_w * result_h * conv2_features\n",
    "fc_features = 500\n",
    "s = conv2_mp.get_shape().as_list()\n",
    "conv_result = tf.reshape(conv2_mp,[-1,s[1]*s[2]*s[3]])\n",
    "fc1_w = tf.Variable(tf.truncated_normal([fc_input_size.value,fc_features],stddev=0.1),dtype=tf.float32)\n",
    "fc1_b = tf.Variable(tf.constant(0.1, shape=[fc_features]),dtype=tf.float32)\n",
    "print(conv_result.shape)\n",
    "# fc1 = tf.nn.relu(tf.matmul(conv_result,fc1_w)+fc1_b)\n",
    "print(fc1_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"MaxPool_106:0\", shape=(?, 7, 7, 50), dtype=float32)\n",
      "Tensor(\"Variable_308/read:0\", shape=(2450, 500), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib import cm\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import fetch_mldata\n",
    " \n",
    "# ネットワークの定義\n",
    " \n",
    "# プレースホルダー\n",
    "x_ = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "# 畳み込み層1\n",
    "conv1_features = 20 # 畳み込み層1の出力次元数\n",
    "max_pool_size1 = 2 # 畳み込み層1のマックスプーリングサイズ\n",
    "conv1_w = tf.Variable(tf.truncated_normal([5, 5, 1, conv1_features], stddev=0.1), dtype=tf.float32) # 畳み込み層1の重み\n",
    "conv1_b = tf.Variable(tf.constant(0.1, shape=[conv1_features]), dtype=tf.float32) # 畳み込み層1のバイアス\n",
    "conv1_c2 = tf.nn.conv2d(x_, conv1_w, strides=[1, 1, 1, 1], padding=\"SAME\") # 畳み込み層1-畳み込み\n",
    "conv1_relu = tf.nn.relu(conv1_c2+conv1_b) # 畳み込み層1-ReLU\n",
    "conv1_mp = tf.nn.max_pool(conv1_relu, ksize=[1, max_pool_size1, max_pool_size1, 1], strides=[1, max_pool_size1, max_pool_size1, 1], padding=\"SAME\") # 畳み込み層1-マックスプーリング\n",
    "# 畳み込み層2\n",
    "conv2_features = 50 # 畳み込み層2の出力次元数\n",
    "max_pool_size2 = 2 # 畳み込み層2のマックスプーリングのサイズ\n",
    "conv2_w = tf.Variable(tf.truncated_normal([5, 5, conv1_features, conv2_features], stddev=0.1), dtype=tf.float32) # 畳み込み層2の重み\n",
    "conv2_b = tf.Variable(tf.constant(0.1, shape=[conv2_features]), dtype=tf.float32) # 畳み込み層2のバイアス\n",
    "conv2_c2 = tf.nn.conv2d(conv1_mp, conv2_w, strides=[1, 1, 1, 1], padding=\"SAME\") # 畳み込み層2-畳み込み\n",
    "conv2_relu = tf.nn.relu(conv2_c2+conv2_b) # 畳み込み層2-ReLU\n",
    "conv2_mp = tf.nn.max_pool(conv2_relu, ksize=[1, max_pool_size2, max_pool_size2, 1], strides=[1, max_pool_size2, max_pool_size2, 1], padding=\"SAME\") # 畳み込み層2-マックスプーリング\n",
    "print(conv2_mp)\n",
    "# 全結合層1\n",
    "result_w = x_.shape[1] // (max_pool_size1*max_pool_size2)\n",
    "result_h = x_.shape[2] // (max_pool_size1*max_pool_size2)\n",
    "fc_input_size = result_w * result_h * conv2_features # 畳み込んだ結果、全結合層に入力する次元数\n",
    "fc_features = 500 # 全結合層の出力次元数（隠れ層の次元数）\n",
    "s = conv2_mp.get_shape().as_list() # [None, result_w, result_h, conv2_features]\n",
    "conv_result = tf.reshape(conv2_mp, [-1, s[1]*s[2]*s[3]]) # 畳み込みの結果を1*N層に変換\n",
    "fc1_w = tf.Variable(tf.truncated_normal([fc_input_size.value, fc_features], stddev=0.1), dtype=tf.float32) # 重み\n",
    "fc1_b = tf.Variable(tf.constant(0.1, shape=[fc_features]), dtype=tf.float32) # バイアス\n",
    "fc1 = tf.nn.relu(tf.matmul(conv_result, fc1_w)+fc1_b) # 全結合層1\n",
    "print(fc1_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
