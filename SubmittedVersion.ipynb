{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.InportLibraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from numpy.random import *\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.InputFieldData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sortPosInfo(labeled_poses,info_name):\n",
    "    labeled_poses.sort(key=lambda x:x[1])\n",
    "    sorted_poses = []\n",
    "    for pos in labeled_poses:\n",
    "        sorted_poses.append(pos[0])\n",
    "    print(\"{0} = {1}\".format(info_name,sorted_poses))\n",
    "    return sorted_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def printFieldData(field):\n",
    "    print(\"Field:\\n----------\")\n",
    "    for row in field:\n",
    "        print(row)\n",
    "    print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputFieldData(text_path):\n",
    "    f = open(text_path)\n",
    "    line = f.readline()\n",
    "    line_count = 1\n",
    "    field_size = int(len(line)/2)\n",
    "#     field = np.empty((0,field_size),int)\n",
    "    field = []\n",
    "    agent_poses = []\n",
    "    goal_poses = []\n",
    "    while line:\n",
    "        last_idx = line.find(\"\\n\")\n",
    "        field_row = []\n",
    "        for i in range(0,last_idx,2):\n",
    "            field_row.append(int(line[i]))\n",
    "            if int(line[i]) % 2 == 0 and int(line[i]) != 0:\n",
    "                agent_data = [[line_count-1,int(i/2)],int(line[i])]\n",
    "                agent_poses.append(agent_data)\n",
    "            if int(line[i]) % 2 == 1 and int(line[i]) != 1:\n",
    "                goal_data = [[line_count-1,int(i/2)],int(line[i])]\n",
    "                goal_poses.append(goal_data)\n",
    "        field.append(field_row)\n",
    "        line = f.readline()\n",
    "        line_count += 1\n",
    "    f.close()\n",
    "    printFieldData(field)\n",
    "    agent_poses = sortPosInfo(agent_poses,\"agents_pos_list\")\n",
    "    goal_pos_list = sortPosInfo(goal_poses,\"goal_pos_list\")\n",
    "    return field,agent_poses,goal_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field:\n",
      "----------\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 3, 0, 0, 0, 7, 0, 4, 1]\n",
      "[1, 0, 1, 0, 1, 0, 0, 0, 1]\n",
      "[1, 0, 1, 0, 0, 0, 1, 0, 1]\n",
      "[1, 5, 6, 0, 1, 0, 0, 2, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "----------\n",
      "agents_pos_list = [[4, 7], [1, 7], [4, 2]]\n",
      "goal_pos_list = [[1, 1], [4, 1], [1, 5]]\n"
     ]
    }
   ],
   "source": [
    "init_field,agent_poses,goal_poses = inputFieldData(\"demoField.txt\")\n",
    "field_row = len(init_field[0])\n",
    "field_col = len(init_field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.DecideActions\n",
    "### action={0:up, 1:right, 2:down, 3:left, 4:stay}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def moveToNextPos(pos,action):\n",
    "    if action == 0:\n",
    "        next_pos = [pos[0]-1,pos[1]]\n",
    "    elif action == 1:\n",
    "        next_pos = [pos[0],pos[1]+1]\n",
    "    elif action == 2:\n",
    "        next_pos = [pos[0]+1,pos[1]]\n",
    "    elif action== 3:\n",
    "        next_pos = [pos[0],pos[1]-1]\n",
    "    else:\n",
    "        next_pos = [pos[0],pos[1]]\n",
    "    return next_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildNetwork(X_train,y,train):\n",
    "    clf = MLPRegressor(solver=\"adam\",random_state=1,max_iter=1000,hidden_layer_sizes=(20,50,10))\n",
    "    print(\"X_train.shape = {0}, y_train.shape={1}\".format(X_train.shape,y_train.shape))\n",
    "    clf.fit(X_train,y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkNextField(action_data,poses,pred_actions,field,agent_num):\n",
    "#     print(\"method_start\")\n",
    "    next_poses = [moveToNextPos(poses[i],pred_actions[i]) for i in range(len(poses))]\n",
    "    next_pos = next_poses[agent_num]\n",
    "    action_flag = True\n",
    "    #行動先が行動可能かどうか判定\n",
    "    if field[next_pos[0]][next_pos[1]] != 1: #行動先が壁でないとき\n",
    "        for i in range(len(next_poses)):\n",
    "            #エージェントの向きと真逆の方向へは移動できない\n",
    "            prev_action = 4 # init\n",
    "            if action_data:\n",
    "                prev_action = action_data[-1][i]\n",
    "            #次の目的地設定後1ステップ目は前回の移動方向を参照して真逆の方向への移動ができない制限を加える必要がある\n",
    "#             elif all_best_action_data:\n",
    "#                 prev_action = all_best_action_data[-1][-1][i]\n",
    "            pred_action = pred_actions[i]\n",
    "            if (prev_action == 0 and pred_action == 2) or (prev_action == 1 and pred_action == 3) or (prev_action == 2 and pred_action == 0) or (prev_action == 3 and pred_action == 1):\n",
    "                action_flag = False\n",
    "#                 print(\"a\")\n",
    "            #行動先に先約があるとき\n",
    "            if agent_num == i: continue\n",
    "            if next_pos == next_poses[i]:\n",
    "                action_flag = False\n",
    "#                 print(\"b\")\n",
    "            #他エージェントと交差するとき\n",
    "            if next_pos == poses[i] and next_poses[i] == poses[agent_num]:\n",
    "                action_flag = False\n",
    "#                 print(\"c\")\n",
    "    else:\n",
    "        action_flag = False\n",
    "    return action_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkAchievingGoal(poses,goal_flags):\n",
    "    for i in range(len(poses)):\n",
    "        if poses[i] == goal_poses[i]:\n",
    "            goal_flags[i] = True\n",
    "    return goal_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkActions(action_data,pred_actions,field,poses,goal_flags):\n",
    "    next_poses = []\n",
    "    exit_flag = False\n",
    "    goal_flags = checkAchievingGoal(poses,goal_flags)\n",
    "    for i in range(len(pred_actions)):\n",
    "        next_poses.append(moveToNextPos(poses[i],pred_actions[i]))\n",
    "        if goal_flags[i]:\n",
    "            pred_actions[i] = 5\n",
    "    for i in range(len(next_poses)):\n",
    "        if goal_flags[i]:\n",
    "            continue\n",
    "        #行動先が行動可能かどうか判定\n",
    "        action_flag = checkNextField(action_data,poses,pred_actions,field,i)\n",
    "        #行動不可能なとき，注目するエージェントの行動先を変更\n",
    "        cnt = 0\n",
    "        while action_flag == False:\n",
    "            pred_actions[i] = int(pred_actions[i] + rand() *3 + 1) % 4\n",
    "            action_flag = checkNextField(action_data,poses,pred_actions,field,i)\n",
    "            cnt += 1\n",
    "            if cnt > 100:\n",
    "                exit_flag = True\n",
    "                break\n",
    "    return pred_actions,exit_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictActions(clf,field):\n",
    "    X_test = np.asarray(field).reshape(1,field_row*field_col)\n",
    "    actions = clf.predict(X_test)[0]\n",
    "    for i in range(len(actions)):\n",
    "        actions[i] = int(actions[i])\n",
    "    if rand() < 0.2:\n",
    "#         for i in range(len(actions)):\n",
    "#             if rand() < 0.5:\n",
    "#                 actions[i] = int(actions[i] + rand() * 3 + 1) % 4\n",
    "        actions[i] = int(actions[i] + rand() * 3 + 1) % 4\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateField(poses,next_poses,field):\n",
    "    for i in range(len(agent_poses)):\n",
    "        pos = poses[i]\n",
    "        next_pos = next_poses[i]\n",
    "        #エージェントがいずれかの方向に進行する場合\n",
    "        if pos != next_pos:\n",
    "            #現在いる地点がいずれかのエージェントのゴール地点でないとき\n",
    "            if field[pos[0]][pos[1]] % 2 == 0:\n",
    "                field[pos[0]][pos[1]] = 0\n",
    "            #現在いる地点がいずれかのエージェントのゴール地点のとき，現在地の値は変更しない\n",
    "            \n",
    "            #遷移先がいずれかのゴール地点でないとき\n",
    "            if field[next_pos[0]][next_pos[1]] % 2 == 0:\n",
    "                field[next_pos[0]][next_pos[1]] = i * 2 + 2\n",
    "            #遷移先がいずれかのゴール地点のとき遷移先の値は変更しない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FIND_ROOT_MAX_LOOP = 30\n",
    "# train_data_cnt = 0\n",
    "# def createTrainData(init_field,init_poses,clf,path_count,best_field_data,best_action_data,last_poses):\n",
    "#     global train_data_cnt\n",
    "#     field_data = [copy.deepcopy(init_field)]\n",
    "#     field = copy.deepcopy(init_field)\n",
    "#     poses = init_poses\n",
    "#     action_data = []\n",
    "#     goal_flags = [False for i in range(len(poses))]\n",
    "#     create_flag = False\n",
    "#     exit_flag = False\n",
    "#     for i in range(FIND_ROOT_MAX_LOOP):\n",
    "# #         print(\"agent_poses = {0}\".format(poses))\n",
    "#         if train_data_cnt > 3:\n",
    "#             pred_actions = predictActions(clf,field)\n",
    "#         else:\n",
    "#             pred_actions = [int(rand()*4) for i in range(len(agent_poses))]\n",
    "#         #予測したアクションに対してチェックを行い，壁や他エージェントにぶつかる挙動を変更する\n",
    "#         actions,exit_flag = checkActions(action_data,pred_actions,field,poses,goal_flags)\n",
    "#         if exit_flag:\n",
    "#             break\n",
    "#         #タイムステップ毎のアクションを保持するaction_dataの末尾に次の行動を追加\n",
    "#         action_data.append(actions)\n",
    "#         #actionsを元に次のfieldへと遷移させる\n",
    "#         next_poses = []\n",
    "#         for j in range(len(agent_poses)):\n",
    "#             next_poses.append(moveToNextPos(poses[j],actions[j]))\n",
    "#         updateField(poses,next_poses,field)\n",
    "#         field_data.append(copy.deepcopy(field))\n",
    "#         poses = next_poses\n",
    "# #         printFieldData(field)\n",
    "#         if goal_flags[0] and goal_flags[1] and goal_flags[2]:\n",
    "#             action_data.append([4,4,4])\n",
    "#             np_field_data = np.asarray(field_data)\n",
    "#             np_action_data = np.asarray(action_data)\n",
    "#             if path_count > np_field_data.shape[0] - 5:\n",
    "#                 path_count = np_field_data.shape[0]\n",
    "#                 clf = buildNetwork(np_field_data.reshape(np_field_data.shape[0],np_field_data.shape[1]*np_field_data.shape[2]),np_action_data)\n",
    "#                 train_data_cnt += 1\n",
    "#                 best_field_data = copy.deepcopy(field_data)\n",
    "#                 best_action_data = copy.deepcopy(action_data)\n",
    "#                 last_poses = copy.deepcopy(poses)\n",
    "#                 create_flag = True\n",
    "#             break\n",
    "#     return last_poses,clf,path_count,best_field_data,best_action_data,create_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FIND_ROOT_MAX_LOOP = 100\n",
    "train_data_cnt = 0\n",
    "def createTrainData(init_field,init_poses,clf,path_count,best_field_data,best_action_data,last_poses):\n",
    "    global train_data_cnt\n",
    "    field_data = [copy.deepcopy(init_field)]\n",
    "    field = copy.deepcopy(init_field)\n",
    "    poses = init_poses\n",
    "    action_data = []\n",
    "    goal_flags = [False for i in range(len(poses))]\n",
    "    create_flag = False\n",
    "    exit_flag = False\n",
    "    first_goal_flag = False\n",
    "    dummy_first_goal_idx = -1\n",
    "    dummy_first_goal_poses = []\n",
    "    for i in range(FIND_ROOT_MAX_LOOP):\n",
    "#         if clf != None:\n",
    "        if train_data_cnt >6:\n",
    "            pred_actions = predictActions(clf,field)\n",
    "        else:\n",
    "            pred_actions = [int(rand()*4) for i in range(len(agents_pos_list))]\n",
    "        #予測したアクションに対してチェックを行い，壁や他エージェントにぶつかる挙動を変更する\n",
    "        actions,exit_flag = checkActions(action_data,pred_actions,field,poses,goal_flags)\n",
    "        if (goal_flags[0] or goal_flags[1] or goal_flags[2]) and first_goal_flag == False:\n",
    "            first_goal_flag = True\n",
    "            dummy_first_goal_idx = len(action_data)\n",
    "            dummy_first_goal_poses = copy.deepcopy(poses)\n",
    "        if exit_flag:\n",
    "            break\n",
    "        #タイムステップ毎のアクションを保持するaction_dataの末尾に次の行動を追加\n",
    "        action_data.append(actions)\n",
    "        #actionsを元に次のfieldへと遷移させる\n",
    "        next_poses = []\n",
    "        for j in range(len(agents_pos_list)):\n",
    "            next_poses.append(moveToNextPos(poses[j],actions[j]))\n",
    "        updateField(poses,next_poses,field)\n",
    "        field_data.append(copy.deepcopy(field))\n",
    "        poses = next_poses\n",
    "        if goal_flags[0] and goal_flags[1] and goal_flags[2]:\n",
    "            action_data.append([4,4,4])\n",
    "            np_field_data = np.asarray(field_data)\n",
    "            np_action_data = np.asarray(action_data)\n",
    "            if path_count > np_field_data.shape[0] - 5:\n",
    "                path_count = np_field_data.shape[0]\n",
    "                clf = buildNetwork(np_field_data.reshape(np_field_data.shape[0],np_field_data.shape[1]*np_field_data.shape[2]),np_action_data)\n",
    "#                 printFieldData(field_data,action_data)\n",
    "                train_data_cnt += 1\n",
    "                best_field_data = copy.deepcopy(field_data)\n",
    "                print(\"dummy:{0}\".format(dummy_first_goal_idx))\n",
    "                global first_goal_field_idx\n",
    "                global first_goal_field_poses\n",
    "                first_goal_field_idx = dummy_first_goal_idx\n",
    "                first_goal_field_poses = copy.deepcopy(dummy_first_goal_poses)\n",
    "                best_action_data = copy.deepcopy(action_data)\n",
    "                last_poses = copy.deepcopy(poses)\n",
    "                create_flag = True\n",
    "            break\n",
    "#     for i in range(30):\n",
    "#         print(field_data[i])\n",
    "#         print(\"action = {0} \\n\".format(action_data[i]))\n",
    "#     print(\"--------------------------------------------------\")\n",
    "    return  last_poses,clf,path_count,best_field_data,best_action_data,create_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runCreatingPath(agent_poses,init_field):\n",
    "    clf = None\n",
    "    path_count = 1e+7\n",
    "    best_field_data = []\n",
    "    best_action_data = []\n",
    "    last_poses = []\n",
    "    create_flag = False\n",
    "    cnt = 0\n",
    "    while train_data_cnt < 10:\n",
    "        init_poses = agent_poses\n",
    "        last_poses,clf,path_count,best_field_data,best_action_data,create_flag = createTrainData(init_field,init_poses,clf,path_count,best_field_data,best_action_data,last_poses)\n",
    "    return best_field_data,best_action_data,last_poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "dshiba-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
